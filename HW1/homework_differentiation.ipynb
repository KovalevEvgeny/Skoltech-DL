{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it easy to google every task please please please try to undestand what's going on. The \"just answer\" thing will be not counted, make sure to present derivation of your solution. It is absolutely OK if you found an answer on web then just exercise in $\\LaTeX$ copying it into here. A good way to derive solutions for these tasks is to derive it for single elements and then generalize to the resulting matrix/vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links: \n",
    "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
    "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
    "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar w.r.t. vector:\n",
    "$$  \n",
    "y = c^Tx,  \\quad x \\in \\mathbb{R}^N \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = c^T\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Solution.** Let's take a derivative for single element of $x$:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx_i} = \\frac{d}{dx_i}\\left(\\sum\\limits_{j=1}^Nc_jx_j\\right) = c_i\n",
    "$$\n",
    "\n",
    "Then we can compute gradient:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\left(\\frac{dy}{dx_1}, \\ldots, \\frac{dy}{dx_N}\\right)^T = \\left(c_1, \\ldots, c_N\\right) = c^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector w.r.t. vector:\n",
    "$$ y = \\sum_{j=1}^{N} cx^T \\quad c \\in \\mathbb{R}^{M} ,x \\in \\mathbb{R}^{N}, cx^T \\in \\mathbb{R}^{M \\times N} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = c\\mathbb{1}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Solution.** Let's take a look at $cx^T$:\n",
    "\n",
    "$$\n",
    "cx^T = \\begin{pmatrix}c_1\\\\\\vdots\\\\c_M\\end{pmatrix}\\begin{pmatrix}x_1\\cdots x_N\\end{pmatrix} = \\begin{pmatrix}c_1x_1\\cdots c_1x_N\\\\\\vdots\\ddots\\vdots\\\\c_Mx_1\\cdots c_Mx_N\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "So, we can rewrite $y$:\n",
    "\n",
    "$$\n",
    "y = \\sum\\limits_{j=1}(cx^T)_j = \\left(c_1\\sum\\limits_{j=1}^Nx_j, \\ldots, c_M\\sum\\limits_{j=1}^Nx_j\\right)\n",
    "$$\n",
    "\n",
    "Let's take a derivative for single element of $y$ and $x$:\n",
    "\n",
    "$$\n",
    "\\frac{dy_i}{dx_k} = c_i\n",
    "$$\n",
    "\n",
    "Then we can compute jacobian:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\begin{pmatrix}\\frac{dy_1}{dx_1}\\cdots \\frac{dy_1}{dx_N}\\\\\\vdots\\ddots\\vdots\\\\\\frac{dy_M}{dx_1}\\cdots \\frac{dy_M}{dx_N}\\end{pmatrix} = \\begin{pmatrix}c_1\\cdots c_1\\\\\\vdots\\ddots\\vdots\\\\c_M\\cdots c_M\\end{pmatrix} = \\begin{pmatrix}c_1\\\\\\vdots\\\\c_M\\end{pmatrix}\\begin{pmatrix}1\\cdots 1\\end{pmatrix} = c\\mathbb{1}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector w.r.t. vector:\n",
    "$$  \n",
    "y = x x^T x , x \\in \\mathbb{R}^{N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = 2xx^T + \\mathrm{diag}\\left(\\|x\\|_2^2\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Solution.** Let's rewrite $y$:\n",
    "\n",
    "$$\n",
    "y = xx^Tx = \\begin{pmatrix}x_1\\\\\\vdots\\\\x_N\\end{pmatrix}\\begin{pmatrix}x_1\\cdots x_N\\end{pmatrix}\\begin{pmatrix}x_1\\\\\\vdots\\\\x_N\\end{pmatrix} = \\begin{pmatrix}x_1\\\\\\vdots\\\\x_N\\end{pmatrix}\\sum\\limits_{j=1}^Nx_j^2 = \\begin{pmatrix}x_1\\sum\\limits_{j=1}^Nx_j^2\\\\\\vdots\\\\x_N\\sum\\limits_{j=1}^Nx_j^2\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Let's take a derivative for single element of $y$ and $x$:\n",
    "\n",
    "$$\n",
    "\\frac{dy_i}{dx_k} = \\begin{cases}2x_ix_k, & i \\neq k\\\\ 2x_i^2 + \\|x\\|_2^2, & i = k\\end{cases}\n",
    "$$\n",
    "\n",
    "Then we can compute jacobian:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\begin{pmatrix}\\frac{dy_1}{dx_1}\\cdots \\frac{dy_1}{dx_N}\\\\\\vdots\\ddots\\vdots\\\\\\frac{dy_N}{dx_1}\\cdots \\frac{dy_N}{dx_N}\\end{pmatrix} = \\begin{pmatrix}2x_1^2 + \\|x\\|_2^2 & \\cdots & 2x_1x_N\\\\\\vdots & \\ddots & \\vdots\\\\2x_1x_N & \\cdots &  2x_N^2 + \\|x\\|_2^2\\end{pmatrix} = 2\\begin{pmatrix}x_1^2 & \\cdots & x_1x_N\\\\\\vdots & \\ddots & \\vdots\\\\x_1x_N & \\cdots &  x_N^2\\end{pmatrix} + I_n\\|x\\|_2^2 = 2xx^T + \\mathrm{diag}\\left(\\|x\\|_2^2\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatives for the parameters of the Dense layer:\n",
    "\n",
    "***Given :***  $$Y = XW, Y \\in \\mathbb{R}^{N \\times OUT}, X \\in \\mathbb{R}^{N \\times IN}, W \\in \\mathbb{R}^{IN \\times OUT} $$ \n",
    "\n",
    "The derivative of the hypothetic loss function w.r.t. to $Y$ is known: $\\Delta Y  \\in \\mathbb{R}^{N \\times OUT}$\n",
    "\n",
    "***Task :*** Please, derive the gradients of the loss w.r.t the weight matrix $W$: $\\Delta W  \\in \\mathbb{R}^{IN \\times OUT}$. Use the chain rule. First, please, derive each element of the $\\Delta W$, then generalize to the matrix form.\n",
    " \n",
    "Useful link: http://cs231n.stanford.edu/vecDerivs.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dL}{dW} = X^T\\frac{dL}{dY}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Solution.** Denote loss by $L$. Then we know $\\frac{dL}{dY}$, and we have to compute $\\frac{dL}{dW}$. We have that $Y = XW$, which means:\n",
    "\n",
    "$$\n",
    "Y_{\\ell, m} = \\sum\\limits_{n=1}^{IN}X_{\\ell, n}W_{n, m}\n",
    "$$\n",
    "\n",
    "Let's compute $W_{i, j}$, an element of matrix $W$. According to the formula for an element of matrix $Y$ above, it appears in $Y_{1, j}, \\ldots, Y_{N, j}$. Hence, using the chain rule, we obtain:\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dW_{i, j}} = \\sum\\limits_{k=1}^N\\frac{dL}{dY_{k, j}}\\frac{dY_{k, j}}{dW_{i, j}} = \\sum\\limits_{k=1}^N\\frac{dL}{dY_{k, j}}X_{k, i} = \\begin{pmatrix}\\frac{dL}{dY_{1, j}}\\cdots \\frac{dL}{dY_{N, j}}\\end{pmatrix}\\begin{pmatrix}X_{1, i}\\\\\\vdots\\\\ X_{N, i}\\end{pmatrix} = \\left(\\frac{dL}{dY}\\right)_{(j)}^TX_{(i)},\n",
    "$$\n",
    "\n",
    "where $\\left(\\frac{dL}{dY}\\right)_{(j)}$ is a $j$-th column of matrix $\\frac{dL}{dY}$, and $X_{(i)}$ is a $i$-th column of matrix $X$.\n",
    "\n",
    "Substituting this to $\\frac{dL}{dW}$, we get:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{dL}{dW} =\\\\\n",
    "&& = \\begin{pmatrix}\\frac{dL}{dW_{1, 1}}&\\cdots&\\frac{dL}{dW_{1, OUT}}\\\\\\vdots&\\ddots&\\vdots\\\\\\frac{dL}{dW_{IN, 1}}&\\cdots&\\frac{dL}{dW_{IN, OUT}}\\end{pmatrix} =\\\\\n",
    "&& = \\begin{pmatrix}\\left(\\frac{dL}{dY}\\right)_{(1)}^TX_{(1)}&\\cdots&\\left(\\frac{dL}{dY}\\right)_{(OUT)}^TX_{(1)}\\\\\\vdots&\\ddots&\\vdots\\\\\\left(\\frac{dL}{dY}\\right)_{(1)}^TX_{(IN)}&\\cdots&\\left(\\frac{dL}{dY}\\right)_{(OUT)}^TX_{(IN)}\\end{pmatrix} =\\\\\n",
    "&& = \\begin{pmatrix}\\left(\\frac{dL}{dY}\\right)_{(1)}^TX_{(1)}&\\cdots&\\left(\\frac{dL}{dY}\\right)_{(1)}^TX_{(IN)}\\\\\\vdots&\\ddots&\\vdots\\\\\\left(\\frac{dL}{dY}\\right)_{(OUT)}^TX_{(1)}&\\cdots&\\left(\\frac{dL}{dY}\\right)_{(OUT)}^TX_{(IN)}\\end{pmatrix}^T =\\\\\n",
    "&& = \\left(\\begin{pmatrix}\\left(\\frac{dL}{dY}\\right)_{(1)}^T\\\\\\vdots\\\\\\left(\\frac{dL}{dY}\\right)_{(OUT)}^T\\end{pmatrix}\\begin{pmatrix}X_{(1)}\\cdots X_{(IN)}\\end{pmatrix}\\right)^T =\\\\\n",
    "&& = \\left(\\left(\\frac{dL}{dY}\\right)^TX\\right)^T =\\\\\n",
    "&& = X^T\\frac{dL}{dY}\n",
    "\\end{eqnarray}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
